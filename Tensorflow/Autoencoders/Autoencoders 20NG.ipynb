{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecthing data..................................\n"
     ]
    }
   ],
   "source": [
    "print(\"Fecthing data..................................\")\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "newsgroups_data = newsgroups_train.data + newsgroups_test.data\n",
    "newsgroups_labels = list(newsgroups_train.target) + list(newsgroups_test.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n",
      "talk.politics.guns\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.target_names[1])\n",
    "print(newsgroups_train.target_names[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_data_downsampled = []\n",
    "newsgroups_labels_downsampled = []\n",
    "for index in range(len(newsgroups_data)):\n",
    "    if newsgroups_labels[index] == 1 or newsgroups_labels[index] == 16:\n",
    "        newsgroups_data_downsampled.append(newsgroups_data[index])\n",
    "        newsgroups_labels_downsampled.append(newsgroups_labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1883"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_labels_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully\n",
      "Turning data into Tf-IDF format................\n",
      "Successfully created bag of words.\n"
     ]
    }
   ],
   "source": [
    "print(\"Data fetched successfully\")\n",
    "print(\"Turning data into Tf-IDF format................\")\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(newsgroups_data_downsampled)\n",
    "\n",
    "print(\"Successfully created bag of words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = vectors[int(0.9 * vectors.shape[0]):]\n",
    "train_data = vectors[:int(0.9 * vectors.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1694, 31911)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_steps = 1800\n",
    "batch_size = 2\n",
    "\n",
    "display_step = 100\n",
    "examples_to_show = 10\n",
    "\n",
    "# Network Parameters\n",
    "num_hidden_1 = 1000 # 1st layer num features\n",
    "# num_hidden_2 = 300 # 2nd layer num features (the latent dim)\n",
    "num_input = train_data.shape[1] # MNIST data input (img shape: 28*28)\n",
    "\n",
    "# tf Graph input (only pictures)\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1])),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_1, num_input])),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_input])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "                                   biases['encoder_b1']))\n",
    "    return layer_1\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
    "                                   biases['decoder_b1']))\n",
    "    return layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X\n",
    "\n",
    "# Define loss and optimizer, minimize the squared error\n",
    "loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.array(vectors.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1883, 31911)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Minibatch Loss: 0.474970\n",
      "Step 1: Minibatch Loss: 0.476070\n",
      "Step 2: Minibatch Loss: 0.476575\n",
      "Step 3: Minibatch Loss: 0.475711\n",
      "Step 4: Minibatch Loss: 0.477324\n",
      "Step 5: Minibatch Loss: 0.474016\n",
      "Step 6: Minibatch Loss: 0.476100\n",
      "Step 7: Minibatch Loss: 0.478570\n",
      "Step 8: Minibatch Loss: 0.477533\n",
      "Step 9: Minibatch Loss: 0.477592\n",
      "Step 10: Minibatch Loss: 0.477416\n",
      "Step 11: Minibatch Loss: 0.475954\n",
      "Step 12: Minibatch Loss: 0.477439\n",
      "Step 13: Minibatch Loss: 0.478193\n",
      "Step 14: Minibatch Loss: 0.475538\n",
      "Step 15: Minibatch Loss: 0.475331\n",
      "Step 16: Minibatch Loss: 0.474821\n",
      "Step 17: Minibatch Loss: 0.476503\n",
      "Step 18: Minibatch Loss: 0.477818\n",
      "Step 19: Minibatch Loss: 0.476572\n",
      "Step 20: Minibatch Loss: 0.478039\n",
      "Step 21: Minibatch Loss: 0.476497\n",
      "Step 22: Minibatch Loss: 0.478013\n",
      "Step 23: Minibatch Loss: 0.477858\n",
      "Step 24: Minibatch Loss: 0.476180\n",
      "Step 25: Minibatch Loss: 0.477518\n",
      "Step 26: Minibatch Loss: 0.476573\n",
      "Step 27: Minibatch Loss: 0.476764\n",
      "Step 28: Minibatch Loss: 0.476145\n",
      "Step 29: Minibatch Loss: 0.477863\n",
      "Step 30: Minibatch Loss: 0.476132\n",
      "Step 31: Minibatch Loss: 0.476894\n",
      "Step 32: Minibatch Loss: 0.477321\n",
      "Step 33: Minibatch Loss: 0.475265\n",
      "Step 34: Minibatch Loss: 0.477058\n",
      "Step 35: Minibatch Loss: 0.475316\n",
      "Step 36: Minibatch Loss: 0.477238\n",
      "Step 37: Minibatch Loss: 0.473445\n",
      "Step 38: Minibatch Loss: 0.476591\n",
      "Step 39: Minibatch Loss: 0.477536\n",
      "Step 40: Minibatch Loss: 0.475596\n",
      "Step 41: Minibatch Loss: 0.475929\n",
      "Step 42: Minibatch Loss: 0.474595\n",
      "Step 43: Minibatch Loss: 0.476291\n",
      "Step 44: Minibatch Loss: 0.475700\n",
      "Step 45: Minibatch Loss: 0.476255\n",
      "Step 46: Minibatch Loss: 0.476290\n",
      "Step 47: Minibatch Loss: 0.477314\n",
      "Step 48: Minibatch Loss: 0.476431\n",
      "Step 49: Minibatch Loss: 0.476992\n",
      "Step 50: Minibatch Loss: 0.477007\n",
      "Step 51: Minibatch Loss: 0.477806\n",
      "Step 52: Minibatch Loss: 0.476828\n",
      "Step 53: Minibatch Loss: 0.478996\n",
      "Step 54: Minibatch Loss: 0.476823\n",
      "Step 55: Minibatch Loss: 0.477174\n",
      "Step 56: Minibatch Loss: 0.475991\n",
      "Step 57: Minibatch Loss: 0.476599\n",
      "Step 58: Minibatch Loss: 0.476359\n",
      "Step 59: Minibatch Loss: 0.477449\n",
      "Step 60: Minibatch Loss: 0.475609\n",
      "Step 61: Minibatch Loss: 0.476602\n",
      "Step 62: Minibatch Loss: 0.476792\n",
      "Step 63: Minibatch Loss: 0.475291\n",
      "Step 64: Minibatch Loss: 0.476946\n",
      "Step 65: Minibatch Loss: 0.477604\n",
      "Step 66: Minibatch Loss: 0.477623\n",
      "Step 67: Minibatch Loss: 0.475275\n",
      "Step 68: Minibatch Loss: 0.476372\n",
      "Step 69: Minibatch Loss: 0.478577\n",
      "Step 70: Minibatch Loss: 0.476154\n",
      "Step 71: Minibatch Loss: 0.478213\n",
      "Step 72: Minibatch Loss: 0.476255\n",
      "Step 73: Minibatch Loss: 0.477297\n",
      "Step 74: Minibatch Loss: 0.475768\n",
      "Step 75: Minibatch Loss: 0.476310\n",
      "Step 76: Minibatch Loss: 0.476128\n",
      "Step 77: Minibatch Loss: 0.476095\n",
      "Step 78: Minibatch Loss: 0.476939\n",
      "Step 79: Minibatch Loss: 0.475958\n",
      "Step 80: Minibatch Loss: 0.475359\n",
      "Step 81: Minibatch Loss: 0.475439\n",
      "Step 82: Minibatch Loss: 0.476068\n",
      "Step 83: Minibatch Loss: 0.478449\n",
      "Step 84: Minibatch Loss: 0.476108\n",
      "Step 85: Minibatch Loss: 0.476764\n",
      "Step 86: Minibatch Loss: 0.478533\n",
      "Step 87: Minibatch Loss: 0.475076\n",
      "Step 88: Minibatch Loss: 0.475740\n",
      "Step 89: Minibatch Loss: 0.475429\n",
      "Step 90: Minibatch Loss: 0.474565\n",
      "Step 91: Minibatch Loss: 0.475803\n",
      "Step 92: Minibatch Loss: 0.477113\n",
      "Step 93: Minibatch Loss: 0.476622\n",
      "Step 94: Minibatch Loss: 0.475135\n",
      "Step 95: Minibatch Loss: 0.476057\n",
      "Step 96: Minibatch Loss: 0.475073\n",
      "Step 97: Minibatch Loss: 0.476396\n",
      "Step 98: Minibatch Loss: 0.477375\n",
      "Step 99: Minibatch Loss: 0.475491\n",
      "Step 100: Minibatch Loss: 0.477119\n",
      "Step 101: Minibatch Loss: 0.475281\n",
      "Step 102: Minibatch Loss: 0.476052\n",
      "Step 103: Minibatch Loss: 0.476625\n",
      "Step 104: Minibatch Loss: 0.476408\n",
      "Step 105: Minibatch Loss: 0.476044\n",
      "Step 106: Minibatch Loss: 0.475935\n",
      "Step 107: Minibatch Loss: 0.477288\n",
      "Step 108: Minibatch Loss: 0.475191\n",
      "Step 109: Minibatch Loss: 0.475781\n",
      "Step 110: Minibatch Loss: 0.476262\n",
      "Step 111: Minibatch Loss: 0.476892\n",
      "Step 112: Minibatch Loss: 0.476344\n",
      "Step 113: Minibatch Loss: 0.476556\n",
      "Step 114: Minibatch Loss: 0.475560\n",
      "Step 115: Minibatch Loss: 0.475581\n",
      "Step 116: Minibatch Loss: 0.475733\n",
      "Step 117: Minibatch Loss: 0.476977\n",
      "Step 118: Minibatch Loss: 0.476370\n",
      "Step 119: Minibatch Loss: 0.474025\n",
      "Step 120: Minibatch Loss: 0.477685\n",
      "Step 121: Minibatch Loss: 0.476510\n",
      "Step 122: Minibatch Loss: 0.477240\n",
      "Step 123: Minibatch Loss: 0.477527\n",
      "Step 124: Minibatch Loss: 0.475997\n",
      "Step 125: Minibatch Loss: 0.475801\n",
      "Step 126: Minibatch Loss: 0.475581\n",
      "Step 127: Minibatch Loss: 0.475991\n",
      "Step 128: Minibatch Loss: 0.474686\n",
      "Step 129: Minibatch Loss: 0.475778\n",
      "Step 130: Minibatch Loss: 0.475424\n",
      "Step 131: Minibatch Loss: 0.474467\n",
      "Step 132: Minibatch Loss: 0.476233\n",
      "Step 133: Minibatch Loss: 0.476106\n",
      "Step 134: Minibatch Loss: 0.477258\n",
      "Step 135: Minibatch Loss: 0.477168\n",
      "Step 136: Minibatch Loss: 0.474299\n",
      "Step 137: Minibatch Loss: 0.476126\n",
      "Step 138: Minibatch Loss: 0.476902\n",
      "Step 139: Minibatch Loss: 0.474776\n",
      "Step 140: Minibatch Loss: 0.477427\n",
      "Step 141: Minibatch Loss: 0.475142\n",
      "Step 142: Minibatch Loss: 0.474930\n",
      "Step 143: Minibatch Loss: 0.475549\n",
      "Step 144: Minibatch Loss: 0.477061\n",
      "Step 145: Minibatch Loss: 0.476328\n",
      "Step 146: Minibatch Loss: 0.478104\n",
      "Step 147: Minibatch Loss: 0.477093\n",
      "Step 148: Minibatch Loss: 0.476008\n",
      "Step 149: Minibatch Loss: 0.477661\n",
      "Step 150: Minibatch Loss: 0.477324\n",
      "Step 151: Minibatch Loss: 0.475863\n",
      "Step 152: Minibatch Loss: 0.477274\n",
      "Step 153: Minibatch Loss: 0.477591\n",
      "Step 154: Minibatch Loss: 0.474931\n",
      "Step 155: Minibatch Loss: 0.476641\n",
      "Step 156: Minibatch Loss: 0.475447\n",
      "Step 157: Minibatch Loss: 0.476938\n",
      "Step 158: Minibatch Loss: 0.476548\n",
      "Step 159: Minibatch Loss: 0.475260\n",
      "Step 160: Minibatch Loss: 0.476966\n",
      "Step 161: Minibatch Loss: 0.475334\n",
      "Step 162: Minibatch Loss: 0.475255\n",
      "Step 163: Minibatch Loss: 0.475547\n",
      "Step 164: Minibatch Loss: 0.474267\n",
      "Step 165: Minibatch Loss: 0.476286\n",
      "Step 166: Minibatch Loss: 0.474469\n",
      "Step 167: Minibatch Loss: 0.474411\n",
      "Step 168: Minibatch Loss: 0.475432\n",
      "Step 169: Minibatch Loss: 0.474979\n",
      "Step 170: Minibatch Loss: 0.474911\n",
      "Step 171: Minibatch Loss: 0.475488\n",
      "Step 172: Minibatch Loss: 0.474016\n",
      "Step 173: Minibatch Loss: 0.472601\n",
      "Step 174: Minibatch Loss: 0.473878\n",
      "Step 175: Minibatch Loss: 0.474770\n",
      "Step 176: Minibatch Loss: 0.473493\n",
      "Step 177: Minibatch Loss: 0.473686\n",
      "Step 178: Minibatch Loss: 0.474430\n",
      "Step 179: Minibatch Loss: 0.472990\n",
      "Step 180: Minibatch Loss: 0.472744\n",
      "Step 181: Minibatch Loss: 0.472926\n",
      "Step 182: Minibatch Loss: 0.474479\n",
      "Step 183: Minibatch Loss: 0.471217\n",
      "Step 184: Minibatch Loss: 0.473609\n",
      "Step 185: Minibatch Loss: 0.474338\n",
      "Step 186: Minibatch Loss: 0.473151\n",
      "Step 187: Minibatch Loss: 0.471645\n",
      "Step 188: Minibatch Loss: 0.472090\n",
      "Step 189: Minibatch Loss: 0.470552\n",
      "Step 190: Minibatch Loss: 0.472853\n",
      "Step 191: Minibatch Loss: 0.472590\n",
      "Step 192: Minibatch Loss: 0.471162\n",
      "Step 193: Minibatch Loss: 0.473274\n",
      "Step 194: Minibatch Loss: 0.471379\n",
      "Step 195: Minibatch Loss: 0.469397\n",
      "Step 196: Minibatch Loss: 0.471422\n",
      "Step 197: Minibatch Loss: 0.470427\n",
      "Step 198: Minibatch Loss: 0.470590\n",
      "Step 199: Minibatch Loss: 0.469674\n",
      "Step 200: Minibatch Loss: 0.471509\n",
      "Step 201: Minibatch Loss: 0.467464\n",
      "Step 202: Minibatch Loss: 0.467849\n",
      "Step 203: Minibatch Loss: 0.467874\n",
      "Step 204: Minibatch Loss: 0.468370\n",
      "Step 205: Minibatch Loss: 0.467938\n",
      "Step 206: Minibatch Loss: 0.468715\n",
      "Step 207: Minibatch Loss: 0.466407\n",
      "Step 208: Minibatch Loss: 0.465155\n",
      "Step 209: Minibatch Loss: 0.465240\n",
      "Step 210: Minibatch Loss: 0.464703\n",
      "Step 211: Minibatch Loss: 0.465456\n",
      "Step 212: Minibatch Loss: 0.464826\n",
      "Step 213: Minibatch Loss: 0.461817\n",
      "Step 214: Minibatch Loss: 0.461367\n",
      "Step 215: Minibatch Loss: 0.462556\n",
      "Step 216: Minibatch Loss: 0.461683\n",
      "Step 217: Minibatch Loss: 0.460147\n",
      "Step 218: Minibatch Loss: 0.459917\n",
      "Step 219: Minibatch Loss: 0.460913\n",
      "Step 220: Minibatch Loss: 0.458724\n",
      "Step 221: Minibatch Loss: 0.459559\n",
      "Step 222: Minibatch Loss: 0.457614\n",
      "Step 223: Minibatch Loss: 0.457626\n",
      "Step 224: Minibatch Loss: 0.455994\n",
      "Step 225: Minibatch Loss: 0.454045\n",
      "Step 226: Minibatch Loss: 0.453314\n",
      "Step 227: Minibatch Loss: 0.454830\n",
      "Step 228: Minibatch Loss: 0.452587\n",
      "Step 229: Minibatch Loss: 0.454002\n",
      "Step 230: Minibatch Loss: 0.450877\n",
      "Step 231: Minibatch Loss: 0.451301\n",
      "Step 232: Minibatch Loss: 0.448716\n",
      "Step 233: Minibatch Loss: 0.448800\n",
      "Step 234: Minibatch Loss: 0.447694\n",
      "Step 235: Minibatch Loss: 0.447486\n",
      "Step 236: Minibatch Loss: 0.445558\n",
      "Step 237: Minibatch Loss: 0.445243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 238: Minibatch Loss: 0.445325\n",
      "Step 239: Minibatch Loss: 0.444930\n",
      "Step 240: Minibatch Loss: 0.444125\n",
      "Step 241: Minibatch Loss: 0.440234\n",
      "Step 242: Minibatch Loss: 0.440234\n",
      "Step 243: Minibatch Loss: 0.440279\n",
      "Step 244: Minibatch Loss: 0.438154\n",
      "Step 245: Minibatch Loss: 0.438886\n",
      "Step 246: Minibatch Loss: 0.438711\n",
      "Step 247: Minibatch Loss: 0.434337\n",
      "Step 248: Minibatch Loss: 0.437322\n",
      "Step 249: Minibatch Loss: 0.435238\n",
      "Step 250: Minibatch Loss: 0.433332\n",
      "Step 251: Minibatch Loss: 0.430027\n",
      "Step 252: Minibatch Loss: 0.432478\n",
      "Step 253: Minibatch Loss: 0.430273\n",
      "Step 254: Minibatch Loss: 0.430560\n",
      "Step 255: Minibatch Loss: 0.429276\n",
      "Step 256: Minibatch Loss: 0.429663\n",
      "Step 257: Minibatch Loss: 0.427857\n",
      "Step 258: Minibatch Loss: 0.426861\n",
      "Step 259: Minibatch Loss: 0.426115\n",
      "Step 260: Minibatch Loss: 0.424281\n",
      "Step 261: Minibatch Loss: 0.423346\n",
      "Step 262: Minibatch Loss: 0.422558\n",
      "Step 263: Minibatch Loss: 0.420988\n",
      "Step 264: Minibatch Loss: 0.420846\n",
      "Step 265: Minibatch Loss: 0.421032\n",
      "Step 266: Minibatch Loss: 0.419636\n",
      "Step 267: Minibatch Loss: 0.420100\n",
      "Step 268: Minibatch Loss: 0.417792\n",
      "Step 269: Minibatch Loss: 0.417394\n",
      "Step 270: Minibatch Loss: 0.416536\n",
      "Step 271: Minibatch Loss: 0.415983\n",
      "Step 272: Minibatch Loss: 0.413445\n",
      "Step 273: Minibatch Loss: 0.412147\n",
      "Step 274: Minibatch Loss: 0.411346\n",
      "Step 275: Minibatch Loss: 0.412026\n",
      "Step 276: Minibatch Loss: 0.412848\n",
      "Step 277: Minibatch Loss: 0.410757\n",
      "Step 278: Minibatch Loss: 0.408575\n",
      "Step 279: Minibatch Loss: 0.406559\n",
      "Step 280: Minibatch Loss: 0.408165\n",
      "Step 281: Minibatch Loss: 0.406393\n",
      "Step 282: Minibatch Loss: 0.405135\n",
      "Step 283: Minibatch Loss: 0.405581\n",
      "Step 284: Minibatch Loss: 0.404052\n",
      "Step 285: Minibatch Loss: 0.402881\n",
      "Step 286: Minibatch Loss: 0.402442\n",
      "Step 287: Minibatch Loss: 0.399730\n",
      "Step 288: Minibatch Loss: 0.401165\n",
      "Step 289: Minibatch Loss: 0.397828\n",
      "Step 290: Minibatch Loss: 0.399500\n",
      "Step 291: Minibatch Loss: 0.397498\n",
      "Step 292: Minibatch Loss: 0.396844\n",
      "Step 293: Minibatch Loss: 0.396073\n",
      "Step 294: Minibatch Loss: 0.395361\n",
      "Step 295: Minibatch Loss: 0.396865\n",
      "Step 296: Minibatch Loss: 0.393541\n",
      "Step 297: Minibatch Loss: 0.396981\n",
      "Step 298: Minibatch Loss: 0.394006\n",
      "Step 299: Minibatch Loss: 0.389217\n",
      "Step 300: Minibatch Loss: 0.392813\n",
      "Step 301: Minibatch Loss: 0.391451\n",
      "Step 302: Minibatch Loss: 0.386801\n",
      "Step 303: Minibatch Loss: 0.389422\n",
      "Step 304: Minibatch Loss: 0.388745\n",
      "Step 305: Minibatch Loss: 0.387136\n",
      "Step 306: Minibatch Loss: 0.386382\n",
      "Step 307: Minibatch Loss: 0.384501\n",
      "Step 308: Minibatch Loss: 0.385113\n",
      "Step 309: Minibatch Loss: 0.386627\n",
      "Step 310: Minibatch Loss: 0.382443\n",
      "Step 311: Minibatch Loss: 0.383944\n",
      "Step 312: Minibatch Loss: 0.380656\n",
      "Step 313: Minibatch Loss: 0.378010\n",
      "Step 314: Minibatch Loss: 0.380078\n",
      "Step 315: Minibatch Loss: 0.378511\n",
      "Step 316: Minibatch Loss: 0.379215\n",
      "Step 317: Minibatch Loss: 0.378202\n",
      "Step 318: Minibatch Loss: 0.375182\n",
      "Step 319: Minibatch Loss: 0.374652\n",
      "Step 320: Minibatch Loss: 0.375215\n",
      "Step 321: Minibatch Loss: 0.376051\n",
      "Step 322: Minibatch Loss: 0.373660\n",
      "Step 323: Minibatch Loss: 0.375096\n",
      "Step 324: Minibatch Loss: 0.372702\n",
      "Step 325: Minibatch Loss: 0.369048\n",
      "Step 326: Minibatch Loss: 0.372373\n",
      "Step 327: Minibatch Loss: 0.371124\n",
      "Step 328: Minibatch Loss: 0.369334\n",
      "Step 329: Minibatch Loss: 0.370107\n",
      "Step 330: Minibatch Loss: 0.367199\n",
      "Step 331: Minibatch Loss: 0.367453\n",
      "Step 332: Minibatch Loss: 0.366636\n",
      "Step 333: Minibatch Loss: 0.367378\n",
      "Step 334: Minibatch Loss: 0.362713\n",
      "Step 335: Minibatch Loss: 0.364789\n",
      "Step 336: Minibatch Loss: 0.364992\n",
      "Step 337: Minibatch Loss: 0.363741\n",
      "Step 338: Minibatch Loss: 0.363354\n",
      "Step 339: Minibatch Loss: 0.359988\n",
      "Step 340: Minibatch Loss: 0.361231\n",
      "Step 341: Minibatch Loss: 0.361940\n",
      "Step 342: Minibatch Loss: 0.362248\n",
      "Step 343: Minibatch Loss: 0.355502\n",
      "Step 344: Minibatch Loss: 0.357279\n",
      "Step 345: Minibatch Loss: 0.356001\n",
      "Step 346: Minibatch Loss: 0.356667\n",
      "Step 347: Minibatch Loss: 0.355419\n",
      "Step 348: Minibatch Loss: 0.355157\n",
      "Step 349: Minibatch Loss: 0.355635\n",
      "Step 350: Minibatch Loss: 0.355225\n",
      "Step 351: Minibatch Loss: 0.353204\n",
      "Step 352: Minibatch Loss: 0.352547\n",
      "Step 353: Minibatch Loss: 0.353477\n",
      "Step 354: Minibatch Loss: 0.351852\n",
      "Step 355: Minibatch Loss: 0.351575\n",
      "Step 356: Minibatch Loss: 0.351031\n",
      "Step 357: Minibatch Loss: 0.348383\n",
      "Step 358: Minibatch Loss: 0.347832\n",
      "Step 359: Minibatch Loss: 0.348657\n",
      "Step 360: Minibatch Loss: 0.345581\n",
      "Step 361: Minibatch Loss: 0.345487\n",
      "Step 362: Minibatch Loss: 0.347072\n",
      "Step 363: Minibatch Loss: 0.345568\n",
      "Step 364: Minibatch Loss: 0.343650\n",
      "Step 365: Minibatch Loss: 0.343971\n",
      "Step 366: Minibatch Loss: 0.340066\n",
      "Step 367: Minibatch Loss: 0.341044\n",
      "Step 368: Minibatch Loss: 0.341986\n",
      "Step 369: Minibatch Loss: 0.342872\n",
      "Step 370: Minibatch Loss: 0.337987\n",
      "Step 371: Minibatch Loss: 0.341844\n",
      "Step 372: Minibatch Loss: 0.338903\n",
      "Step 373: Minibatch Loss: 0.338968\n",
      "Step 374: Minibatch Loss: 0.339145\n",
      "Step 375: Minibatch Loss: 0.338168\n",
      "Step 376: Minibatch Loss: 0.338660\n",
      "Step 377: Minibatch Loss: 0.337564\n",
      "Step 378: Minibatch Loss: 0.335184\n",
      "Step 379: Minibatch Loss: 0.333440\n",
      "Step 380: Minibatch Loss: 0.333607\n",
      "Step 381: Minibatch Loss: 0.335220\n",
      "Step 382: Minibatch Loss: 0.330734\n",
      "Step 383: Minibatch Loss: 0.333098\n",
      "Step 384: Minibatch Loss: 0.333956\n",
      "Step 385: Minibatch Loss: 0.334052\n",
      "Step 386: Minibatch Loss: 0.331620\n",
      "Step 387: Minibatch Loss: 0.330160\n",
      "Step 388: Minibatch Loss: 0.329170\n",
      "Step 389: Minibatch Loss: 0.328636\n",
      "Step 390: Minibatch Loss: 0.329335\n",
      "Step 391: Minibatch Loss: 0.330081\n",
      "Step 392: Minibatch Loss: 0.328567\n",
      "Step 393: Minibatch Loss: 0.329848\n",
      "Step 394: Minibatch Loss: 0.325820\n",
      "Step 395: Minibatch Loss: 0.328567\n",
      "Step 396: Minibatch Loss: 0.325105\n",
      "Step 397: Minibatch Loss: 0.323401\n",
      "Step 398: Minibatch Loss: 0.324253\n",
      "Step 399: Minibatch Loss: 0.325300\n",
      "Step 400: Minibatch Loss: 0.323031\n",
      "Step 401: Minibatch Loss: 0.322497\n",
      "Step 402: Minibatch Loss: 0.319957\n",
      "Step 403: Minibatch Loss: 0.321868\n",
      "Step 404: Minibatch Loss: 0.319954\n",
      "Step 405: Minibatch Loss: 0.321169\n",
      "Step 406: Minibatch Loss: 0.322029\n",
      "Step 407: Minibatch Loss: 0.320151\n",
      "Step 408: Minibatch Loss: 0.318742\n",
      "Step 409: Minibatch Loss: 0.317910\n",
      "Step 410: Minibatch Loss: 0.319733\n",
      "Step 411: Minibatch Loss: 0.316342\n",
      "Step 412: Minibatch Loss: 0.315307\n",
      "Step 413: Minibatch Loss: 0.316079\n",
      "Step 414: Minibatch Loss: 0.313333\n",
      "Step 415: Minibatch Loss: 0.315822\n",
      "Step 416: Minibatch Loss: 0.312691\n",
      "Step 417: Minibatch Loss: 0.313354\n",
      "Step 418: Minibatch Loss: 0.312739\n",
      "Step 419: Minibatch Loss: 0.311801\n",
      "Step 420: Minibatch Loss: 0.313338\n",
      "Step 421: Minibatch Loss: 0.313743\n",
      "Step 422: Minibatch Loss: 0.311278\n",
      "Step 423: Minibatch Loss: 0.310125\n",
      "Step 424: Minibatch Loss: 0.310829\n",
      "Step 425: Minibatch Loss: 0.309715\n",
      "Step 426: Minibatch Loss: 0.309987\n",
      "Step 427: Minibatch Loss: 0.310914\n",
      "Step 428: Minibatch Loss: 0.308051\n",
      "Step 429: Minibatch Loss: 0.309244\n",
      "Step 430: Minibatch Loss: 0.309350\n",
      "Step 431: Minibatch Loss: 0.307596\n",
      "Step 432: Minibatch Loss: 0.310471\n",
      "Step 433: Minibatch Loss: 0.307672\n",
      "Step 434: Minibatch Loss: 0.305293\n",
      "Step 435: Minibatch Loss: 0.306516\n",
      "Step 436: Minibatch Loss: 0.305884\n",
      "Step 437: Minibatch Loss: 0.303490\n",
      "Step 438: Minibatch Loss: 0.304245\n",
      "Step 439: Minibatch Loss: 0.302324\n",
      "Step 440: Minibatch Loss: 0.302107\n",
      "Step 441: Minibatch Loss: 0.302232\n",
      "Step 442: Minibatch Loss: 0.301437\n",
      "Step 443: Minibatch Loss: 0.303203\n",
      "Step 444: Minibatch Loss: 0.301327\n",
      "Step 445: Minibatch Loss: 0.298079\n",
      "Step 446: Minibatch Loss: 0.299744\n",
      "Step 447: Minibatch Loss: 0.301521\n",
      "Step 448: Minibatch Loss: 0.297608\n",
      "Step 449: Minibatch Loss: 0.296167\n",
      "Step 450: Minibatch Loss: 0.299100\n",
      "Step 451: Minibatch Loss: 0.297532\n",
      "Step 452: Minibatch Loss: 0.297931\n",
      "Step 453: Minibatch Loss: 0.298268\n",
      "Step 454: Minibatch Loss: 0.296972\n",
      "Step 455: Minibatch Loss: 0.296685\n",
      "Step 456: Minibatch Loss: 0.296074\n",
      "Step 457: Minibatch Loss: 0.294824\n",
      "Step 458: Minibatch Loss: 0.293316\n",
      "Step 459: Minibatch Loss: 0.293822\n",
      "Step 460: Minibatch Loss: 0.293031\n",
      "Step 461: Minibatch Loss: 0.295194\n",
      "Step 462: Minibatch Loss: 0.292239\n",
      "Step 463: Minibatch Loss: 0.291503\n",
      "Step 464: Minibatch Loss: 0.292834\n",
      "Step 465: Minibatch Loss: 0.292042\n",
      "Step 466: Minibatch Loss: 0.294061\n",
      "Step 467: Minibatch Loss: 0.289116\n",
      "Step 468: Minibatch Loss: 0.291702\n",
      "Step 469: Minibatch Loss: 0.290866\n",
      "Step 470: Minibatch Loss: 0.288980\n",
      "Step 471: Minibatch Loss: 0.288666\n",
      "Step 472: Minibatch Loss: 0.289042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 473: Minibatch Loss: 0.289550\n",
      "Step 474: Minibatch Loss: 0.288015\n",
      "Step 475: Minibatch Loss: 0.289864\n",
      "Step 476: Minibatch Loss: 0.289087\n",
      "Step 477: Minibatch Loss: 0.287014\n",
      "Step 478: Minibatch Loss: 0.285217\n",
      "Step 479: Minibatch Loss: 0.284521\n",
      "Step 480: Minibatch Loss: 0.285172\n",
      "Step 481: Minibatch Loss: 0.285681\n",
      "Step 482: Minibatch Loss: 0.284947\n",
      "Step 483: Minibatch Loss: 0.286479\n",
      "Step 484: Minibatch Loss: 0.285777\n",
      "Step 485: Minibatch Loss: 0.283862\n",
      "Step 486: Minibatch Loss: 0.285049\n",
      "Step 487: Minibatch Loss: 0.284359\n",
      "Step 488: Minibatch Loss: 0.282706\n",
      "Step 489: Minibatch Loss: 0.282288\n",
      "Step 490: Minibatch Loss: 0.281327\n",
      "Step 491: Minibatch Loss: 0.281429\n",
      "Step 492: Minibatch Loss: 0.285188\n",
      "Step 493: Minibatch Loss: 0.280188\n",
      "Step 494: Minibatch Loss: 0.279307\n",
      "Step 495: Minibatch Loss: 0.280821\n",
      "Step 496: Minibatch Loss: 0.280460\n",
      "Step 497: Minibatch Loss: 0.280950\n",
      "Step 498: Minibatch Loss: 0.281584\n",
      "Step 499: Minibatch Loss: 0.278961\n",
      "Step 500: Minibatch Loss: 0.275918\n",
      "Step 501: Minibatch Loss: 0.277831\n",
      "Step 502: Minibatch Loss: 0.275237\n",
      "Step 503: Minibatch Loss: 0.279026\n",
      "Step 504: Minibatch Loss: 0.277216\n",
      "Step 505: Minibatch Loss: 0.277454\n",
      "Step 506: Minibatch Loss: 0.279829\n",
      "Step 507: Minibatch Loss: 0.275716\n",
      "Step 508: Minibatch Loss: 0.275410\n",
      "Step 509: Minibatch Loss: 0.275389\n",
      "Step 510: Minibatch Loss: 0.275552\n",
      "Step 511: Minibatch Loss: 0.272747\n",
      "Step 512: Minibatch Loss: 0.276084\n",
      "Step 513: Minibatch Loss: 0.274720\n",
      "Step 514: Minibatch Loss: 0.272124\n",
      "Step 515: Minibatch Loss: 0.273914\n",
      "Step 516: Minibatch Loss: 0.272331\n",
      "Step 517: Minibatch Loss: 0.273989\n",
      "Step 518: Minibatch Loss: 0.272385\n",
      "Step 519: Minibatch Loss: 0.271506\n",
      "Step 520: Minibatch Loss: 0.275052\n",
      "Step 521: Minibatch Loss: 0.271532\n",
      "Step 522: Minibatch Loss: 0.271489\n",
      "Step 523: Minibatch Loss: 0.272503\n",
      "Step 524: Minibatch Loss: 0.269340\n",
      "Step 525: Minibatch Loss: 0.271357\n",
      "Step 526: Minibatch Loss: 0.268961\n",
      "Step 527: Minibatch Loss: 0.267931\n",
      "Step 528: Minibatch Loss: 0.268064\n",
      "Step 529: Minibatch Loss: 0.270374\n",
      "Step 530: Minibatch Loss: 0.270210\n",
      "Step 531: Minibatch Loss: 0.269443\n",
      "Step 532: Minibatch Loss: 0.266625\n",
      "Step 533: Minibatch Loss: 0.270126\n",
      "Step 534: Minibatch Loss: 0.266097\n",
      "Step 535: Minibatch Loss: 0.267976\n",
      "Step 536: Minibatch Loss: 0.266309\n",
      "Step 537: Minibatch Loss: 0.263898\n",
      "Step 538: Minibatch Loss: 0.265298\n",
      "Step 539: Minibatch Loss: 0.265758\n",
      "Step 540: Minibatch Loss: 0.266807\n",
      "Step 541: Minibatch Loss: 0.266558\n",
      "Step 542: Minibatch Loss: 0.264273\n",
      "Step 543: Minibatch Loss: 0.265021\n",
      "Step 544: Minibatch Loss: 0.263428\n",
      "Step 545: Minibatch Loss: 0.263888\n",
      "Step 546: Minibatch Loss: 0.263585\n",
      "Step 547: Minibatch Loss: 0.263291\n",
      "Step 548: Minibatch Loss: 0.263423\n",
      "Step 549: Minibatch Loss: 0.264287\n",
      "Step 550: Minibatch Loss: 0.261430\n",
      "Step 551: Minibatch Loss: 0.261589\n",
      "Step 552: Minibatch Loss: 0.260815\n",
      "Step 553: Minibatch Loss: 0.262320\n",
      "Step 554: Minibatch Loss: 0.262237\n",
      "Step 555: Minibatch Loss: 0.261547\n",
      "Step 556: Minibatch Loss: 0.263380\n",
      "Step 557: Minibatch Loss: 0.259905\n",
      "Step 558: Minibatch Loss: 0.258945\n",
      "Step 559: Minibatch Loss: 0.261442\n",
      "Step 560: Minibatch Loss: 0.260561\n",
      "Step 561: Minibatch Loss: 0.257967\n",
      "Step 562: Minibatch Loss: 0.258707\n",
      "Step 563: Minibatch Loss: 0.258718\n",
      "Step 564: Minibatch Loss: 0.259006\n",
      "Step 565: Minibatch Loss: 0.259859\n",
      "Step 566: Minibatch Loss: 0.260634\n",
      "Step 567: Minibatch Loss: 0.257136\n",
      "Step 568: Minibatch Loss: 0.256914\n",
      "Step 569: Minibatch Loss: 0.257574\n",
      "Step 570: Minibatch Loss: 0.256738\n",
      "Step 571: Minibatch Loss: 0.257570\n",
      "Step 572: Minibatch Loss: 0.256058\n",
      "Step 573: Minibatch Loss: 0.255313\n",
      "Step 574: Minibatch Loss: 0.256273\n",
      "Step 575: Minibatch Loss: 0.254113\n",
      "Step 576: Minibatch Loss: 0.257278\n",
      "Step 577: Minibatch Loss: 0.254305\n",
      "Step 578: Minibatch Loss: 0.253111\n",
      "Step 579: Minibatch Loss: 0.254632\n",
      "Step 580: Minibatch Loss: 0.253541\n",
      "Step 581: Minibatch Loss: 0.253187\n",
      "Step 582: Minibatch Loss: 0.255344\n",
      "Step 583: Minibatch Loss: 0.253213\n",
      "Step 584: Minibatch Loss: 0.251558\n",
      "Step 585: Minibatch Loss: 0.254225\n",
      "Step 586: Minibatch Loss: 0.250790\n",
      "Step 587: Minibatch Loss: 0.252073\n",
      "Step 588: Minibatch Loss: 0.253934\n",
      "Step 589: Minibatch Loss: 0.252484\n",
      "Step 590: Minibatch Loss: 0.252852\n",
      "Step 591: Minibatch Loss: 0.254298\n",
      "Step 592: Minibatch Loss: 0.252118\n",
      "Step 593: Minibatch Loss: 0.251160\n",
      "Step 594: Minibatch Loss: 0.251191\n",
      "Step 595: Minibatch Loss: 0.250733\n",
      "Step 596: Minibatch Loss: 0.249455\n",
      "Step 597: Minibatch Loss: 0.249469\n",
      "Step 598: Minibatch Loss: 0.250723\n",
      "Step 599: Minibatch Loss: 0.249261\n",
      "Step 600: Minibatch Loss: 0.247952\n",
      "Step 601: Minibatch Loss: 0.249589\n",
      "Step 602: Minibatch Loss: 0.249194\n",
      "Step 603: Minibatch Loss: 0.249655\n",
      "Step 604: Minibatch Loss: 0.248237\n",
      "Step 605: Minibatch Loss: 0.248938\n",
      "Step 606: Minibatch Loss: 0.247773\n",
      "Step 607: Minibatch Loss: 0.249542\n",
      "Step 608: Minibatch Loss: 0.248330\n",
      "Step 609: Minibatch Loss: 0.248330\n",
      "Step 610: Minibatch Loss: 0.248048\n",
      "Step 611: Minibatch Loss: 0.248006\n",
      "Step 612: Minibatch Loss: 0.245572\n",
      "Step 613: Minibatch Loss: 0.248152\n",
      "Step 614: Minibatch Loss: 0.245732\n",
      "Step 615: Minibatch Loss: 0.245345\n",
      "Step 616: Minibatch Loss: 0.245426\n",
      "Step 617: Minibatch Loss: 0.247570\n",
      "Step 618: Minibatch Loss: 0.243759\n",
      "Step 619: Minibatch Loss: 0.245535\n",
      "Step 620: Minibatch Loss: 0.244249\n",
      "Step 621: Minibatch Loss: 0.244859\n",
      "Step 622: Minibatch Loss: 0.245469\n",
      "Step 623: Minibatch Loss: 0.244838\n",
      "Step 624: Minibatch Loss: 0.245674\n",
      "Step 625: Minibatch Loss: 0.244355\n",
      "Step 626: Minibatch Loss: 0.243072\n",
      "Step 627: Minibatch Loss: 0.244074\n",
      "Step 628: Minibatch Loss: 0.243227\n",
      "Step 629: Minibatch Loss: 0.243923\n",
      "Step 630: Minibatch Loss: 0.243767\n",
      "Step 631: Minibatch Loss: 0.242610\n",
      "Step 632: Minibatch Loss: 0.242307\n",
      "Step 633: Minibatch Loss: 0.244474\n",
      "Step 634: Minibatch Loss: 0.242940\n",
      "Step 635: Minibatch Loss: 0.241967\n",
      "Step 636: Minibatch Loss: 0.242595\n",
      "Step 637: Minibatch Loss: 0.241766\n",
      "Step 638: Minibatch Loss: 0.240262\n",
      "Step 639: Minibatch Loss: 0.242162\n",
      "Step 640: Minibatch Loss: 0.240927\n",
      "Step 641: Minibatch Loss: 0.241854\n",
      "Step 642: Minibatch Loss: 0.241660\n",
      "Step 643: Minibatch Loss: 0.239788\n",
      "Step 644: Minibatch Loss: 0.240832\n",
      "Step 645: Minibatch Loss: 0.242382\n",
      "Step 646: Minibatch Loss: 0.238152\n",
      "Step 647: Minibatch Loss: 0.237736\n",
      "Step 648: Minibatch Loss: 0.238415\n",
      "Step 649: Minibatch Loss: 0.240657\n",
      "Step 650: Minibatch Loss: 0.237818\n",
      "Step 651: Minibatch Loss: 0.238190\n",
      "Step 652: Minibatch Loss: 0.237239\n",
      "Step 653: Minibatch Loss: 0.238359\n",
      "Step 654: Minibatch Loss: 0.237648\n",
      "Step 655: Minibatch Loss: 0.237565\n",
      "Step 656: Minibatch Loss: 0.237118\n",
      "Step 657: Minibatch Loss: 0.237719\n",
      "Step 658: Minibatch Loss: 0.236838\n",
      "Step 659: Minibatch Loss: 0.238148\n",
      "Step 660: Minibatch Loss: 0.235481\n",
      "Step 661: Minibatch Loss: 0.237235\n",
      "Step 662: Minibatch Loss: 0.236006\n",
      "Step 663: Minibatch Loss: 0.237808\n",
      "Step 664: Minibatch Loss: 0.237386\n",
      "Step 665: Minibatch Loss: 0.236309\n",
      "Step 666: Minibatch Loss: 0.235612\n",
      "Step 667: Minibatch Loss: 0.236430\n",
      "Step 668: Minibatch Loss: 0.236763\n",
      "Step 669: Minibatch Loss: 0.235146\n",
      "Step 670: Minibatch Loss: 0.236985\n",
      "Step 671: Minibatch Loss: 0.233604\n",
      "Step 672: Minibatch Loss: 0.233156\n",
      "Step 673: Minibatch Loss: 0.233775\n",
      "Step 674: Minibatch Loss: 0.233624\n",
      "Step 675: Minibatch Loss: 0.234163\n",
      "Step 676: Minibatch Loss: 0.234729\n",
      "Step 677: Minibatch Loss: 0.235267\n",
      "Step 678: Minibatch Loss: 0.234652\n",
      "Step 679: Minibatch Loss: 0.232286\n",
      "Step 680: Minibatch Loss: 0.234264\n",
      "Step 681: Minibatch Loss: 0.232953\n",
      "Step 682: Minibatch Loss: 0.232157\n",
      "Step 683: Minibatch Loss: 0.232277\n",
      "Step 684: Minibatch Loss: 0.232227\n",
      "Step 685: Minibatch Loss: 0.230038\n",
      "Step 686: Minibatch Loss: 0.231665\n",
      "Step 687: Minibatch Loss: 0.232834\n",
      "Step 688: Minibatch Loss: 0.230674\n",
      "Step 689: Minibatch Loss: 0.231688\n",
      "Step 690: Minibatch Loss: 0.229477\n",
      "Step 691: Minibatch Loss: 0.229236\n",
      "Step 692: Minibatch Loss: 0.233006\n",
      "Step 693: Minibatch Loss: 0.230763\n",
      "Step 694: Minibatch Loss: 0.230810\n",
      "Step 695: Minibatch Loss: 0.230311\n",
      "Step 696: Minibatch Loss: 0.230357\n",
      "Step 697: Minibatch Loss: 0.231367\n",
      "Step 698: Minibatch Loss: 0.228638\n",
      "Step 699: Minibatch Loss: 0.228782\n",
      "Step 700: Minibatch Loss: 0.227619\n",
      "Step 701: Minibatch Loss: 0.229007\n",
      "Step 702: Minibatch Loss: 0.229853\n",
      "Step 703: Minibatch Loss: 0.229548\n",
      "Step 704: Minibatch Loss: 0.228260\n",
      "Step 705: Minibatch Loss: 0.229942\n",
      "Step 706: Minibatch Loss: 0.228637\n",
      "Step 707: Minibatch Loss: 0.228463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 708: Minibatch Loss: 0.227593\n",
      "Step 709: Minibatch Loss: 0.228099\n",
      "Step 710: Minibatch Loss: 0.228308\n",
      "Step 711: Minibatch Loss: 0.226424\n",
      "Step 712: Minibatch Loss: 0.227437\n",
      "Step 713: Minibatch Loss: 0.226786\n",
      "Step 714: Minibatch Loss: 0.226697\n",
      "Step 715: Minibatch Loss: 0.228257\n",
      "Step 716: Minibatch Loss: 0.226096\n",
      "Step 717: Minibatch Loss: 0.226630\n",
      "Step 718: Minibatch Loss: 0.226641\n",
      "Step 719: Minibatch Loss: 0.225598\n",
      "Step 720: Minibatch Loss: 0.225656\n",
      "Step 721: Minibatch Loss: 0.227118\n",
      "Step 722: Minibatch Loss: 0.225311\n",
      "Step 723: Minibatch Loss: 0.224506\n",
      "Step 724: Minibatch Loss: 0.225464\n",
      "Step 725: Minibatch Loss: 0.225126\n",
      "Step 726: Minibatch Loss: 0.223403\n",
      "Step 727: Minibatch Loss: 0.224429\n",
      "Step 728: Minibatch Loss: 0.225543\n",
      "Step 729: Minibatch Loss: 0.224182\n",
      "Step 730: Minibatch Loss: 0.224638\n",
      "Step 731: Minibatch Loss: 0.223829\n",
      "Step 732: Minibatch Loss: 0.224685\n",
      "Step 733: Minibatch Loss: 0.223051\n",
      "Step 734: Minibatch Loss: 0.224341\n",
      "Step 735: Minibatch Loss: 0.224895\n",
      "Step 736: Minibatch Loss: 0.223650\n",
      "Step 737: Minibatch Loss: 0.223763\n",
      "Step 738: Minibatch Loss: 0.222792\n",
      "Step 739: Minibatch Loss: 0.223945\n",
      "Step 740: Minibatch Loss: 0.223023\n",
      "Step 741: Minibatch Loss: 0.223147\n",
      "Step 742: Minibatch Loss: 0.222216\n",
      "Step 743: Minibatch Loss: 0.222729\n",
      "Step 744: Minibatch Loss: 0.220699\n",
      "Step 745: Minibatch Loss: 0.223302\n",
      "Step 746: Minibatch Loss: 0.220308\n",
      "Step 747: Minibatch Loss: 0.223194\n",
      "Step 748: Minibatch Loss: 0.219570\n",
      "Step 749: Minibatch Loss: 0.222484\n",
      "Step 750: Minibatch Loss: 0.221824\n",
      "Step 751: Minibatch Loss: 0.221161\n",
      "Step 752: Minibatch Loss: 0.221501\n",
      "Step 753: Minibatch Loss: 0.220683\n",
      "Step 754: Minibatch Loss: 0.220921\n",
      "Step 755: Minibatch Loss: 0.221652\n",
      "Step 756: Minibatch Loss: 0.221001\n",
      "Step 757: Minibatch Loss: 0.221629\n",
      "Step 758: Minibatch Loss: 0.221388\n",
      "Step 759: Minibatch Loss: 0.220580\n",
      "Step 760: Minibatch Loss: 0.221202\n",
      "Step 761: Minibatch Loss: 0.219276\n",
      "Step 762: Minibatch Loss: 0.219467\n",
      "Step 763: Minibatch Loss: 0.219909\n",
      "Step 764: Minibatch Loss: 0.220220\n",
      "Step 765: Minibatch Loss: 0.219800\n",
      "Step 766: Minibatch Loss: 0.219264\n",
      "Step 767: Minibatch Loss: 0.219034\n",
      "Step 768: Minibatch Loss: 0.219828\n",
      "Step 769: Minibatch Loss: 0.218082\n",
      "Step 770: Minibatch Loss: 0.219080\n",
      "Step 771: Minibatch Loss: 0.218308\n",
      "Step 772: Minibatch Loss: 0.217993\n",
      "Step 773: Minibatch Loss: 0.217731\n",
      "Step 774: Minibatch Loss: 0.217901\n",
      "Step 775: Minibatch Loss: 0.216861\n",
      "Step 776: Minibatch Loss: 0.217385\n",
      "Step 777: Minibatch Loss: 0.217576\n",
      "Step 778: Minibatch Loss: 0.217991\n",
      "Step 779: Minibatch Loss: 0.216949\n",
      "Step 780: Minibatch Loss: 0.217931\n",
      "Step 781: Minibatch Loss: 0.215307\n",
      "Step 782: Minibatch Loss: 0.217634\n",
      "Step 783: Minibatch Loss: 0.217043\n",
      "Step 784: Minibatch Loss: 0.217788\n",
      "Step 785: Minibatch Loss: 0.216667\n",
      "Step 786: Minibatch Loss: 0.215546\n",
      "Step 787: Minibatch Loss: 0.217568\n",
      "Step 788: Minibatch Loss: 0.217383\n",
      "Step 789: Minibatch Loss: 0.215131\n",
      "Step 790: Minibatch Loss: 0.215607\n",
      "Step 791: Minibatch Loss: 0.216433\n",
      "Step 792: Minibatch Loss: 0.216391\n",
      "Step 793: Minibatch Loss: 0.217549\n",
      "Step 794: Minibatch Loss: 0.214072\n",
      "Step 795: Minibatch Loss: 0.216754\n",
      "Step 796: Minibatch Loss: 0.215717\n",
      "Step 797: Minibatch Loss: 0.215262\n",
      "Step 798: Minibatch Loss: 0.215701\n",
      "Step 799: Minibatch Loss: 0.213945\n",
      "Step 800: Minibatch Loss: 0.214375\n",
      "Step 801: Minibatch Loss: 0.214939\n",
      "Step 802: Minibatch Loss: 0.216240\n",
      "Step 803: Minibatch Loss: 0.214114\n",
      "Step 804: Minibatch Loss: 0.215836\n",
      "Step 805: Minibatch Loss: 0.214529\n",
      "Step 806: Minibatch Loss: 0.212401\n",
      "Step 807: Minibatch Loss: 0.215140\n",
      "Step 808: Minibatch Loss: 0.213747\n",
      "Step 809: Minibatch Loss: 0.214376\n",
      "Step 810: Minibatch Loss: 0.214443\n",
      "Step 811: Minibatch Loss: 0.213833\n",
      "Step 812: Minibatch Loss: 0.212928\n",
      "Step 813: Minibatch Loss: 0.211453\n",
      "Step 814: Minibatch Loss: 0.214186\n",
      "Step 815: Minibatch Loss: 0.213762\n",
      "Step 816: Minibatch Loss: 0.212295\n",
      "Step 817: Minibatch Loss: 0.213095\n",
      "Step 818: Minibatch Loss: 0.211958\n",
      "Step 819: Minibatch Loss: 0.212416\n",
      "Step 820: Minibatch Loss: 0.213006\n",
      "Step 821: Minibatch Loss: 0.211385\n",
      "Step 822: Minibatch Loss: 0.211552\n",
      "Step 823: Minibatch Loss: 0.212722\n",
      "Step 824: Minibatch Loss: 0.213161\n",
      "Step 825: Minibatch Loss: 0.211480\n",
      "Step 826: Minibatch Loss: 0.211582\n",
      "Step 827: Minibatch Loss: 0.211660\n",
      "Step 828: Minibatch Loss: 0.211260\n",
      "Step 829: Minibatch Loss: 0.211046\n",
      "Step 830: Minibatch Loss: 0.210407\n",
      "Step 831: Minibatch Loss: 0.211635\n",
      "Step 832: Minibatch Loss: 0.210068\n",
      "Step 833: Minibatch Loss: 0.210746\n",
      "Step 834: Minibatch Loss: 0.210445\n",
      "Step 835: Minibatch Loss: 0.212122\n",
      "Step 836: Minibatch Loss: 0.210468\n",
      "Step 837: Minibatch Loss: 0.209416\n",
      "Step 838: Minibatch Loss: 0.211948\n",
      "Step 839: Minibatch Loss: 0.209065\n",
      "Step 840: Minibatch Loss: 0.210518\n",
      "Step 841: Minibatch Loss: 0.209688\n",
      "Step 842: Minibatch Loss: 0.208897\n",
      "Step 843: Minibatch Loss: 0.208999\n",
      "Step 844: Minibatch Loss: 0.208657\n",
      "Step 845: Minibatch Loss: 0.208939\n",
      "Step 846: Minibatch Loss: 0.209758\n",
      "Step 847: Minibatch Loss: 0.207762\n",
      "Step 848: Minibatch Loss: 0.209991\n",
      "Step 849: Minibatch Loss: 0.208782\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Training\n",
    "for index in range(850):\n",
    "    data = vec[index * batch_size: (index + 1) * batch_size]\n",
    "#     data = data.todense()\n",
    "#     print()\n",
    "    # Run optimization op (backprop) and cost op (to get loss value)\n",
    "    _, l = sess.run([optimizer, loss], feed_dict={X: data})\n",
    "    # Display logs per step\n",
    "#     if index % display_step == 0 or index == 1:\n",
    "    print('Step %i: Minibatch Loss: %f' % (index, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data = []\n",
    "g = sess.run(decoder_op, feed_dict={X:vec})\n",
    "reconstructed_data = list(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data_reduced_dim = []\n",
    "g = sess.run(encoder_op, feed_dict={X:vec})\n",
    "reconstructed_data_reduced_dim = list(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Accuracy of original data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predictions:  97.88359788359789 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "log_reg = linear_model.LogisticRegression()\n",
    "log_reg.fit(vec[:int(0.9 * len(reconstructed_data)) ], newsgroups_labels_downsampled[:int(0.9 * len(reconstructed_data))])\n",
    "predicted_labels = log_reg.predict(vec[int(0.9 * len(reconstructed_data)):])\n",
    "score = accuracy_score(newsgroups_labels_downsampled[int(0.9 * len(reconstructed_data)):],predicted_labels)\n",
    "print(\"Accuracy of predictions: \" ,score * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Accuracy of Reconstructed data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predictions:  94.70899470899471 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "log_reg = linear_model.LogisticRegression()\n",
    "log_reg.fit(reconstructed_data[:int(0.9 * len(reconstructed_data)) ], newsgroups_labels_downsampled[:int(0.9 * len(reconstructed_data))])\n",
    "predicted_labels = log_reg.predict(reconstructed_data[int(0.9 * len(reconstructed_data)):])\n",
    "score = accuracy_score(newsgroups_labels_downsampled[int(0.9 * len(reconstructed_data)):],predicted_labels)\n",
    "print(\"Accuracy of predictions: \" ,score * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Accuracy of data in reduced dimensions(1000)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predictions:  97.35449735449735 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "log_reg = linear_model.LogisticRegression()\n",
    "log_reg.fit(reconstructed_data_reduced_dim[:int(0.9 * len(reconstructed_data_reduced_dim)) ], newsgroups_labels_downsampled[:int(0.9 * len(reconstructed_data))])\n",
    "predicted_labels = log_reg.predict(reconstructed_data_reduced_dim[int(0.9 * len(reconstructed_data)):])\n",
    "score = accuracy_score(newsgroups_labels_downsampled[int(0.9 * len(reconstructed_data)):],predicted_labels)\n",
    "print(\"Accuracy of predictions: \" ,score * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_original_data = euclidean_distances(vec)\n",
    "distances_reconstructed_data = euclidean_distances(reconstructed_data)\n",
    "distances_reduced_dim_data = euclidean_distances(reconstructed_data_reduced_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1883, 1883)\n",
      "(1883, 1883)\n",
      "(1883, 1883)\n"
     ]
    }
   ],
   "source": [
    "print(distances_original_data.shape)\n",
    "print(distances_reconstructed_data.shape)\n",
    "print(distances_reduced_dim_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[341, 239, 704, 1784, 1680, 254, 1060, 1219, 836, 39, 235, 1112, 1066, 1837, 307, 311, 746, 607, 433, 521]\n",
      "[1777, 985, 1700, 1041, 1290, 1701, 497, 1183, 953, 1112, 311, 743, 1066, 622, 652, 727, 355, 692, 514, 631]\n",
      "[1777, 985, 1700, 1041, 1290, 1701, 497, 1183, 953, 1112, 311, 743, 1066, 622, 652, 727, 355, 692, 514, 631]\n"
     ]
    }
   ],
   "source": [
    "test_index = 20\n",
    "test_data_distances = distances_original_data[test_index]\n",
    "test_recons_ditances = distances_reconstructed_data[test_index]\n",
    "test_data_reduced_distances = distances_reconstructed_data[test_index]\n",
    "original_nearest_neighs = sorted(range(len(test_data_distances)), key=lambda i: test_data_distances[i], reverse=True)[:20]\n",
    "recons_nearest_neighs = sorted(range(len(test_recons_ditances)), key=lambda i: test_recons_ditances[i], reverse=True)[:20]\n",
    "reduced_nearest_neighs = sorted(range(len(test_data_reduced_distances)), key=lambda i: test_data_reduced_distances[i], reverse=True)[:20]\n",
    "print(original_nearest_neighs)\n",
    "print(recons_nearest_neighs)\n",
    "print(reduced_nearest_neighs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
